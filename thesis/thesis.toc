\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Intriguing Properties of Neural Networks}{1}{section.1.1}% 
\contentsline {section}{\numberline {1.2}Activation Functions and Robustness}{2}{section.1.2}% 
\contentsline {section}{\numberline {1.3}Structure of the Thesis}{3}{section.1.3}% 
\contentsline {part}{I\hspace {1em}Fundamentals}{5}{part.1}% 
\contentsline {chapter}{\numberline {2}Neural Networks}{7}{chapter.2}% 
\contentsline {section}{\numberline {2.1}Definition}{7}{section.2.1}% 
\contentsline {paragraph}{}{8}{section*.4}% 
\contentsline {section}{\numberline {2.2}Training}{8}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Loss Function}{9}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Gradient Descent}{9}{subsection.2.2.2}% 
\contentsline {section}{\numberline {2.3}Activation Functions}{12}{section.2.3}% 
\contentsline {section}{\numberline {2.4}CNNs: Convolutional Neural Networks}{15}{section.2.4}% 
\contentsline {section}{\numberline {2.5}From Neural Networks to Deep Neural Networks}{17}{section.2.5}% 
\contentsline {chapter}{\numberline {3}Adversarial Examples Theory}{21}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Another Optimization problem}{22}{section.3.1}% 
\contentsline {subsection}{\numberline {3.1.1}Fast Gradient Sign Method}{23}{subsection.3.1.1}% 
\contentsline {subsection}{\numberline {3.1.2}Projected Gradient Descent}{24}{subsection.3.1.2}% 
\contentsline {subsection}{\numberline {3.1.3}White, Grey and Black Box Attacks}{24}{subsection.3.1.3}% 
\contentsline {section}{\numberline {3.2}Defenses}{25}{section.3.2}% 
\contentsline {subsection}{\numberline {3.2.1}Detection Methods}{25}{subsection.3.2.1}% 
\contentsline {subsection}{\numberline {3.2.2}Robust Optimization and Adversarial Training}{26}{subsection.3.2.2}% 
\contentsline {subsection}{\numberline {3.2.3}Provable Robustness}{27}{subsection.3.2.3}% 
\contentsline {chapter}{\numberline {4}Non-Parametric Activation Functions}{29}{chapter.4}% 
\contentsline {section}{\numberline {4.1}Adaptive Piece-Wise Linear Activation Functions}{30}{section.4.1}% 
\contentsline {section}{\numberline {4.2}Spline Activation Functions}{30}{section.4.2}% 
\contentsline {section}{\numberline {4.3}Maxout Functions}{31}{section.4.3}% 
\contentsline {section}{\numberline {4.4}Kernel-Based Activation Functions}{31}{section.4.4}% 
\contentsline {part}{II\hspace {1em}Robustness of Kafnets}{35}{part.2}% 
\contentsline {chapter}{\numberline {5}Related Works}{37}{chapter.5}% 
\contentsline {section}{\numberline {5.1}K-Winners Take All}{37}{section.5.1}% 
\contentsline {section}{\numberline {5.2}Smooth Adversarial Training}{38}{section.5.2}% 
\contentsline {chapter}{\numberline {6}Solution Approach}{41}{chapter.6}% 
\contentsline {section}{\numberline {6.1}KAFs May Be Good Candidates}{41}{section.6.1}% 
\contentsline {section}{\numberline {6.2}Fast is Better than Free Adversarial Training}{46}{section.6.2}% 
\contentsline {chapter}{\numberline {7}Evaluation}{49}{chapter.7}% 
\contentsline {section}{\numberline {7.1}VGG Inspired Architectures Results}{51}{section.7.1}% 
\contentsline {section}{\numberline {7.2}Exploding Gradients with KafNets}{55}{section.7.2}% 
\contentsline {section}{\numberline {7.3}ResNet20 Inspired Architectures Results}{59}{section.7.3}% 
\contentsline {chapter}{\numberline {8}Conclusions and Future Works}{63}{chapter.8}% 
\contentsline {section}{\numberline {8.1}Conclusions}{63}{section.8.1}% 
\contentsline {section}{\numberline {8.2}Future Works}{64}{section.8.2}% 
