\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Intriguing Properties of Neural Networks}{1}{section.1.1}% 
\contentsline {section}{\numberline {1.2}Smooth Activation Functions and Robustness}{2}{section.1.2}% 
\contentsline {section}{\numberline {1.3}Structure of the Thesis}{2}{section.1.3}% 
\contentsline {chapter}{\numberline {2}Fundamentals}{3}{chapter.2}% 
\contentsline {section}{\numberline {2.1}Deep Neural Networks}{3}{section.2.1}% 
\contentsline {subsection}{\numberline {2.1.1}Definition}{3}{subsection.2.1.1}% 
\contentsline {paragraph}{}{4}{section*.3}% 
\contentsline {subsection}{\numberline {2.1.2}Training}{5}{subsection.2.1.2}% 
\contentsline {subsubsection}{Loss Function}{5}{section*.5}% 
\contentsline {subsubsection}{Gradient Descent}{5}{section*.6}% 
\contentsline {subsection}{\numberline {2.1.3}Activation Functions}{9}{subsection.2.1.3}% 
\contentsline {subsection}{\numberline {2.1.4}CNNs: Convolutional Neural Networks}{11}{subsection.2.1.4}% 
\contentsline {subsection}{\numberline {2.1.5}From Neural Networks to Deep Neural Networks}{13}{subsection.2.1.5}% 
\contentsline {section}{\numberline {2.2}Adversarial Examples Theory}{16}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Another Optimization problem}{17}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Fast Gradient Sign Method}{18}{subsection.2.2.2}% 
\contentsline {subsection}{\numberline {2.2.3}Projected Gradient Descent}{19}{subsection.2.2.3}% 
\contentsline {subsection}{\numberline {2.2.4}White, Grey and Black Box Attacks}{20}{subsection.2.2.4}% 
\contentsline {section}{\numberline {2.3}Defenses}{20}{section.2.3}% 
\contentsline {subsection}{\numberline {2.3.1}Detection Methods}{21}{subsection.2.3.1}% 
\contentsline {subsection}{\numberline {2.3.2}Provable Robustness}{22}{subsection.2.3.2}% 
\contentsline {subsection}{\numberline {2.3.3}Adversarial Training}{22}{subsection.2.3.3}% 
\contentsline {section}{\numberline {2.4}Kernel Based Activation Functions}{22}{section.2.4}% 
\contentsline {chapter}{\numberline {3}Related Works}{23}{chapter.3}% 
\contentsline {section}{\numberline {3.1}K-Winners Take All}{23}{section.3.1}% 
\contentsline {section}{\numberline {3.2}Smooth Adversarial Training}{23}{section.3.2}% 
\contentsline {chapter}{\numberline {4}Solution Approach}{25}{chapter.4}% 
\contentsline {section}{\numberline {4.1}Lipschitz Constant Approach}{25}{section.4.1}% 
\contentsline {section}{\numberline {4.2}Fast is Better than Free Adversarial Training}{25}{section.4.2}% 
\contentsline {chapter}{\numberline {5}Evaluation}{27}{chapter.5}% 
\contentsline {section}{\numberline {5.1}VGG Inspired Architectures Results}{27}{section.5.1}% 
\contentsline {section}{\numberline {5.2}Explofing Gradients with KafNets}{27}{section.5.2}% 
\contentsline {section}{\numberline {5.3}ResNet20 Inspired Architectures Results}{27}{section.5.3}% 
\contentsline {chapter}{\numberline {6}Future Works}{29}{chapter.6}% 
\contentsline {chapter}{\numberline {7}Conclusions}{31}{chapter.7}% 
