\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Intriguing Properties of Neural Networks}{1}{section.1.1}% 
\contentsline {section}{\numberline {1.2}Smooth Activation Functions and Robustness}{1}{section.1.2}% 
\contentsline {section}{\numberline {1.3}Structure of the Thesis}{1}{section.1.3}% 
\contentsline {part}{I\hspace {1em}Fundamentals}{3}{part.1}% 
\contentsline {chapter}{\numberline {2}Neural Networks}{5}{chapter.2}% 
\contentsline {section}{\numberline {2.1}Definition}{5}{section.2.1}% 
\contentsline {paragraph}{}{6}{section*.3}% 
\contentsline {section}{\numberline {2.2}Training}{6}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Loss Function}{7}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Gradient Descent}{7}{subsection.2.2.2}% 
\contentsline {section}{\numberline {2.3}Activation Functions}{10}{section.2.3}% 
\contentsline {section}{\numberline {2.4}CNNs: Convolutional Neural Networks}{13}{section.2.4}% 
\contentsline {section}{\numberline {2.5}From Neural Networks to Deep Neural Networks}{15}{section.2.5}% 
\contentsline {chapter}{\numberline {3}Adversarial Examples Theory}{19}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Another Optimization problem}{20}{section.3.1}% 
\contentsline {subsection}{\numberline {3.1.1}Fast Gradient Sign Method}{21}{subsection.3.1.1}% 
\contentsline {subsection}{\numberline {3.1.2}Projected Gradient Descent}{22}{subsection.3.1.2}% 
\contentsline {subsection}{\numberline {3.1.3}White, Grey and Black Box Attacks}{22}{subsection.3.1.3}% 
\contentsline {section}{\numberline {3.2}Defenses}{23}{section.3.2}% 
\contentsline {subsection}{\numberline {3.2.1}Detection Methods}{23}{subsection.3.2.1}% 
\contentsline {subsection}{\numberline {3.2.2}Robust Optimization}{24}{subsection.3.2.2}% 
\contentsline {subsection}{\numberline {3.2.3}Provable Robustness}{25}{subsection.3.2.3}% 
\contentsline {chapter}{\numberline {4}Non-Parametric Activation Functions}{27}{chapter.4}% 
\contentsline {section}{\numberline {4.1}Adaptive Piece-Wise Linear Activation Functions}{28}{section.4.1}% 
\contentsline {section}{\numberline {4.2}Spline Activation Functions}{28}{section.4.2}% 
\contentsline {section}{\numberline {4.3}Maxout Functions}{29}{section.4.3}% 
\contentsline {section}{\numberline {4.4}Kernel-Based Activation Functions}{29}{section.4.4}% 
\contentsline {part}{II\hspace {1em}Robustness of Kafnets}{33}{part.2}% 
\contentsline {chapter}{\numberline {5}Related Works}{35}{chapter.5}% 
\contentsline {section}{\numberline {5.1}K-Winners Take All}{35}{section.5.1}% 
\contentsline {section}{\numberline {5.2}Smooth Adversarial Training}{36}{section.5.2}% 
\contentsline {chapter}{\numberline {6}Solution Approach}{39}{chapter.6}% 
\contentsline {section}{\numberline {6.1}KAFs May Be Good Candidates}{39}{section.6.1}% 
\contentsline {section}{\numberline {6.2}Fast is Better than Free Adversarial Training}{44}{section.6.2}% 
\contentsline {chapter}{\numberline {7}Evaluation}{47}{chapter.7}% 
\contentsline {section}{\numberline {7.1}VGG Inspired Architectures Results}{48}{section.7.1}% 
\contentsline {section}{\numberline {7.2}Exploding Gradients with KafNets}{49}{section.7.2}% 
\contentsline {section}{\numberline {7.3}ResNet20 Inspired Architectures Results}{49}{section.7.3}% 
\contentsline {chapter}{\numberline {8}Future Works}{51}{chapter.8}% 
\contentsline {chapter}{\numberline {9}Conclusions}{53}{chapter.9}% 
