\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Intriguing Properties of Neural Networks}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Smooth Activation Functions and Robustness}{1}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Structure of the Thesis}{1}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentals}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Deep Neural Networks}{3}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Definition}{3}{subsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Graphic representation of a one layer NN also know as MLP(ref. )\relax }}{4}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A Feedforward Neural Network with 3 hidden layers(ref. Michael A. Nielsen, Neural Networks and Deep Learning, Determination Press', 2015)\relax }}{5}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fnn}{{2.2}{5}{A Feedforward Neural Network with 3 hidden layers(ref. Michael A. Nielsen, Neural Networks and Deep Learning, Determination Press', 2015)\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Training}{5}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Loss Function}{5}{section*.5}\protected@file@percent }
\newlabel{erm}{{2.1}{5}{Loss Function}{equation.2.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gradient Descent}{5}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Activation Functions}{6}{subsection.2.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}CNNs: Convolutional Neural Networks}{6}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}From Neural Networks to Deep Neural Networks}{6}{subsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Adversarial Examples Theory}{6}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Defenses}{6}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Kernel Based Activation Functions}{6}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Works}{7}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}K-Winners Take All}{7}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Smooth Adversarial Training}{7}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Solution Approach}{9}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Lipschitz Constant Approach}{9}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Fast is Better than Free Adversarial Training}{9}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Evaluation}{11}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}VGG Inspired Architectures Results}{11}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Explofing Gradients with KafNets}{11}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}ResNet20 Inspired Architectures Results}{11}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Future Works}{13}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusions}{15}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
